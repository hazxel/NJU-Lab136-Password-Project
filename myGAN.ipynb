{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from data_prep import Password as P\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.input_size = P.n_letters\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = 2\n",
    "        \n",
    "        self.i2h = nn.Linear(self.input_size + self.hidden_size, self.hidden_size)\n",
    "        self.i2o = nn.Linear(self.input_size + self.hidden_size, self.output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "    \n",
    "    def train(self, input_tensor, target_tensor, criterion = nn.NLLLoss(), learning_rate = 0.005):\n",
    "        hidden = self.initHidden()\n",
    "        self.zero_grad()\n",
    "        \n",
    "        for i in range(input_tensor.size()[0]):\n",
    "            output, hidden = self(input_tensor[i], hidden)\n",
    "            \n",
    "        loss = criterion(output, target_tensor)\n",
    "        loss.backward()\n",
    "        \n",
    "        for p in self.parameters():\n",
    "            p.data.add_(-learning_rate, p.grad.data)\n",
    "\n",
    "        return output, loss.item()\n",
    "    \n",
    "    def discriminate(self, input_tensor):\n",
    "        hidden = self.initHidden()\n",
    "        for i in range(input_tensor.size()[0]):\n",
    "            output, hidden = self(input_tensor[i], hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.input_size = P.n_letters\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = P.n_letters\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_size)\n",
    "        self.h2o = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.hidden = self.initHiddenZeros()\n",
    "\n",
    "    def forward(self, input):\n",
    "        output, self.hidden = self.lstm(input.view(1,1,-1), self.hidden)\n",
    "        output = self.h2o(output)\n",
    "        output = self.dropout(output)\n",
    "        output = F.log_softmax(output,dim=2)\n",
    "        return output\n",
    "\n",
    "    def initHiddenZeros(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_size),\n",
    "                torch.zeros(1, 1, self.hidden_size))\n",
    "    \n",
    "    def initHiddenRand(self):\n",
    "        return (torch.rand(1,1, self.hidden_size), \n",
    "                torch.rand(1,1, self.hidden_size))\n",
    "    \n",
    "    def generatePassTensor(self, max_length = 18):\n",
    "        start_letter = p.passwords_string[random.randint(0,len(p.passwords_string) - 1)][0]\n",
    "        with torch.no_grad():\n",
    "            input_tensor = P.passwordToInputTensor(start_letter)\n",
    "            self.hidden = self.initHiddenZeros()\n",
    "            password = start_letter\n",
    "\n",
    "            for c in range(max_length):\n",
    "                output = self(input_tensor[0])\n",
    "                output = output.view(1,-1)\n",
    "                topv, topi = output.topk(1)\n",
    "                topi = topi[0][0]\n",
    "                if topi == P.n_letters - 1:\n",
    "                    break\n",
    "                else:\n",
    "                    letter = P.all_letters[topi]\n",
    "                    password += letter\n",
    "                input_tensor = P.passwordToInputTensor(letter)\n",
    "        \n",
    "        return P.passwordToInputTensor(password)\n",
    "        \n",
    "    \n",
    "    def generate_N(self, p, n_generate = 100, max_length = 18):\n",
    "        generate_list = []\n",
    "\n",
    "        for i in range(n_generate):\n",
    "            start_letter = p.passwords_string[random.randint(0,len(p.passwords_string) - 1)][0]\n",
    "            with torch.no_grad():\n",
    "                input_tensor = P.passwordToInputTensor(start_letter)\n",
    "                self.hidden = self.initHiddenZeros()\n",
    "                output_password = start_letter\n",
    "\n",
    "                for c in range(max_length):\n",
    "                    output = self(input_tensor[0])\n",
    "                    output = output.view(1,-1)\n",
    "                    topv, topi = output.topk(1)\n",
    "                    topi = topi[0][0]\n",
    "                    if topi == P.n_letters - 1:\n",
    "                        break\n",
    "                    else:\n",
    "                        letter = P.all_letters[topi]\n",
    "                        output_password += letter\n",
    "                    input_tensor = P.passwordToInputTensor(letter)\n",
    "                    \n",
    "            generate_list.append(output_password)\n",
    "            \n",
    "        return generate_list\n",
    "\n",
    "    \n",
    "    def pre_train(self, input_line_tensor, target_line_tensor):\n",
    "        target_line_tensor.unsqueeze_(-1)\n",
    "        self.hidden = self.initHiddenZeros()\n",
    "\n",
    "        criterion = nn.NLLLoss()\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=0.1)\n",
    "\n",
    "        self.zero_grad()\n",
    "        loss = torch.tensor(0, dtype = torch.float32, requires_grad = True)\n",
    "\n",
    "        for i in range(input_line_tensor.size(0)):\n",
    "            output = self(input_line_tensor[i])\n",
    "            output = output.view(1,-1)\n",
    "            l = criterion(output, target_line_tensor[i])\n",
    "            loss = loss + l\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        return output, loss.item() / input_line_tensor.size(0)\n",
    "    \n",
    "    \n",
    "    def train(self, D, p, criterion = nn.NLLLoss(), learning_rate = 0.005, max_length = 18):\n",
    "        start_letter = p.passwords_string[random.randint(0,len(p.passwords_string) - 1)][0]\n",
    "        input_tensor = P.passwordToInputTensor(start_letter)\n",
    "        output_tensor = input_tensor\n",
    "        self.hidden = self.initHiddenZeros()\n",
    "       \n",
    "        for c in range(max_length):\n",
    "            output = self(input_tensor[0])\n",
    "            output = output.view(1,-1)\n",
    "            topv, topi = output.topk(1)\n",
    "            topi = topi[0][0]\n",
    "            if topi == P.n_letters - 1:\n",
    "                break\n",
    "            else:\n",
    "                letter = P.all_letters[topi]\n",
    "            input_tensor = P.passwordToInputTensor(letter)\n",
    "            output_tensor = torch.cat((output_tensor, torch.exp(input_tensor)), -3)\n",
    "            \n",
    "        output = D.discriminate(output_tensor)\n",
    "        target_tensor = torch.tensor([1], dtype = torch.long)\n",
    "        loss = criterion(output, target_tensor)\n",
    "        loss.backward()\n",
    "        \n",
    "        for p in self.parameters():\n",
    "            p.data.add_(-learning_rate, p.grad.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Generator(128)\n",
    "d = Discriminator(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initializing passwords...\n",
      "DEBUG:root:Loading from existing json file...\n",
      "INFO:root:Done initializing passwords.\n"
     ]
    }
   ],
   "source": [
    "p = P()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train_iters = 1000\n",
    "print_every = 1000\n",
    "loss_trend = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:---------- Pre-training generator ----------\n",
      "DEBUG:root:Iter: 0 Loss: 4.384539286295573\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"---------- Pre-training generator ----------\")\n",
    "for i in range(pre_train_iters):\n",
    "    pas = p.poopPassword()\n",
    "    input_tensor = P.passwordToInputTensor(pas)\n",
    "    target_tensor = P.passwordToTargetTensor(pas)\n",
    "    output, loss = g.pre_train(input_tensor, target_tensor)\n",
    "    \n",
    "    \n",
    "    if i % print_every == 0:\n",
    "        logging.debug(\"Iter: \"+ str(i)+\" Loss: \"+str(loss))\n",
    "        loss_trend.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:---------- Adversarial Training ----------\n",
      "\n",
      "INFO:root:----------------- 1 / 5 -----------------\n",
      "INFO:root:Training discriminator...\n",
      "DEBUG:root:Feeding generated data...\n",
      "DEBUG:root:Fake data classification accuracy: 0.71\n",
      "DEBUG:root:Feeding genuine data...\n",
      "DEBUG:root:Total classification accuracy: 0.695\n",
      "INFO:root:Done training discriminator.\n",
      "INFO:root:Training generator...\n",
      "INFO:root:Done training generator.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lannanananaanannana', 'nanalananaanananana', '0annananananananana', 'bananananananannaan', 'sananananananananan', 'sanannananannannana', 'Jnaananaananananana', '0ananananaanananana', 'Lananananananananan', '1nanananananananaan', '0aaananananaananana', 'inaananannanananana', 'dananananananaanann', 'yanaaananananananan', 'lananananananananan', 'pananannananananana', 'ananananananananana', '1ananananananananan', 'sananananananananan', 'bananlananlanananaa', 'baanananananannanaa', 'snanaanlananannanan', 'nnanananananananana', '0anananlaalananaana', 'tananananananaanana', 'jananaananananlanan', 'Danannananaanannana', 'rnanannananaananana', '1anaananaananananaa', 'canananaanananaanan', 'mananalananananaana', '0anananananananaana', 'bllanananananananan', '4ananaanaananananan', '0ananananananananan', 'canaaanananaananana', 'lanananananlananann', 'cananananananananan', '6annannanananananna', '1ananlananaannanann', 'dananananananananan', 'Nanananaananananana', '4ananananananananan', 'vananananananananan', 'anannanaananananana', 'anananaanananaannan', 'rannananananaananan', '1aanananananannanna', 'tananananannananana', '0ananananananaanana', 'Dananaanananananana', 'dananananananananan', 'tanannanananananana', 'lanannnanananananan', 'kananaanananananana', 'tanaanaananaannaana', '2anlanananaanananan', 'nanananaananaananan', 'manaananananananaan', 'sananananananananan', 'maanananananananana', 'nanananannannananan', 'fananaanananannanan', 'janananaanananannan', 'kanaananananananana', '0ananananannnannana', 'kananaanannaananana', 'alaananananaannanan', '8nananananananaanaa', 'pananananananananan', '9aanananananananana', '2ananananananananan', 'mnanananananananana', 'onannanaanannnanana', '3ananananananananan', 'Ananananananananana', '1anananannanananana', 'lananaananaanananan', '1anananadananananaa', 'dannananananananana', 'waanananannanananan', '3annanananananaanan', '8ananaananaanaanana', '$anannanananananaan', 'janananaaananananan', 'qananananannananlaa', 'janalanananaananann', '1ananananananananan', 'inannnanananananana', 'dananananananananan', 'cnananananananaanan', '6ananaaaannanananan', 'mananananananananan', 'kanaananananananana', '1ananananananananan', 'Pananananananananan', 'mannanaanaaanananna', '6aanananannanannann', 'mananananananananan', '3anannananannananan'] 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:----------------- 2 / 5 -----------------\n",
      "INFO:root:Training discriminator...\n",
      "DEBUG:root:Feeding generated data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['erinin', 'loninin1', 'moninin', 'irinini', 'fonderin', 'roninie', '8oninin', 'monind', '0oninie', 'Aoninin', 'honinin', 'loninin', 'condin', 'irinin', 'coninie1', 'ushinie1', 'irinin', '4orindo', 'soninin', '12355555', 'joninin', 'iritin', '12355555', 'arinin', '0uninin', '3oninin', 'Goninis', '12359', '9oninin', '1235559', '0oninin', '3oninin', 'yoninin', 'condin', 'voninin', 'doninie', 'koninin', 'shinin', 'donichos', 'boninin', 'joninin', 'soninin', 'arinin', 'arinini', '1259', 'goninin1', 'irindo', 'doning', 'toninin', '0oninie', '0undon', 'doninin', 'loninin', 'loninin', 'arinie', 'jomindo', 'arinin', '0oninin', 'joninin', '7oninin', '6orindo', 'monind', 'borinie', 'roninin', 'fonico', 'coninin', 'boninin', 'boninin', 'loninin', 'boninis', 'bonicho', 'Boninin', 'loninin', 'zuninin', 'lovinin1', 'sondon', 'Longin', 'bondon', '9oninin', '12355555', '6oninin', 'soninin', '12355555', 'morinin', 'irichin', 'goninin', 'roninin1', 'zoninin', 'arinin', 'morinin', 'arinin', 'poninin', 'woninin', 'toninin', 'boninin', 'forinin', '6oninin', 'moninin', 'goninin', 'Rorinin'] 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Fake data classification accuracy: 0.79\n",
      "DEBUG:root:Feeding genuine data...\n",
      "DEBUG:root:Total classification accuracy: 0.805\n",
      "INFO:root:Done training discriminator.\n",
      "INFO:root:Training generator...\n",
      "INFO:root:Done training generator.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0ooooo', 'aooooo1', 'lyoooooo', '2oooooo', 'ioooooooo', 'joyoo', 'lyoooooo', 'moooooooooooooooooo', 'koooo', 'loooooooooo', 'Jooy', 'Cooooo', 'ayoooooooo', '7ooooyooooooooooooo', 'jooooooooooooooo', '6ooooooooooooo', 'rooyooooooooooooooo', '1oo', 'eoooooooooooooooooo', 'boooooooooo', 'poooyooooooooooo', 'kooyoooooooooooo', '5ooooooooooo', '2ooyooooyoooooooooo', 'booooooo', 'rooooooooooo', 'koooooooooooooooo', 'nooooooooyooo', '0ooyoo1', 'mooooooooo', 'poooo', 'dooooooooooooooooo', '9ooooo', 'fooyooooooooooooo', 'hoooooooooooooooooo', 'moooooo', 'roooo', 'mo1oooooo', '7eooyoooooooooooooo', '5oyoooooooo', 'jyooooooooooooooooo', 'hooy', 'koy', '1ooyoooooooooooo', 'noooooooo', 'Hoooooooooooooooo', 'koooyoooooyooooooo1', 'hoooy', 'hoooooooooooyoooooo', 'hoooo', 'booyoooooo', 'moooooooo', 'hooyooooooooooooooo', '9yooooooooooooooooo', 'jooooooooooooooo', 'sooyoooooooo', 'Nooyo', 'Doyoo', 'aoooyoo', 'toooooooooooooooooo', 'Joyooooo', 'oooyoo', 'poyoooooooooooooooo', 'soooo', 'koooooooooooo', 'soyooooooo', 'kooooyooooooooooooo', 'looy', 'Toooooooooooooooooo', 'noooooooooo', 'toooyooooyooooooooo', 'hyoyooooooo', 'aooyooooooooooooooo', 'jooooooo', 'soooyoooooooooooooo', 'aooooooooooo', 'aooooooooooooooo', 'ioooyoooooooooo', '1oooooooooooooooooo', '1oooooooooooooooooo', 'woooooooooooooooooo', 'joooooooooooooooooo', 'dooooooooooooo', 'coooooooo', '11oo', 'roooooooooooooooooo', 'moooyooooooo', 'iyooo', '4ooooooooooooooooo', 'aooooooooo', 'looooooo', 'qoooooooooo', 'Woo', 'gooooooo', 'byooooooo', 'hoooyoooo', '2oooooooooooooo', '6oooooooooooooooooo', 'rooooooo', 'toooooooooooooooooo'] 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:----------------- 3 / 5 -----------------\n",
      "INFO:root:Training discriminator...\n",
      "DEBUG:root:Feeding generated data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['02325', '62323', 'Manilla', '52323', 'ranilla', 'janilla', 'nanilla', '32323', '23555', '23545', '0anilla', 'ganilla', 'manilla', 'janilla', 'sanilla', 'banilill', 'Qanilla', 'manielill', 'canilla', 'hanilill', 'sanilla', 'canilla', 'iligilla', 'danilla', 'sanilill', 'lanilla', 'sanillalla', 'mingelill', 'Vanilla', '23555', 'aligilla', 'nanille', 'Aanilla', 'raniella', 'kerine', 'shanilla', 'rabilla', 'Banilla', '3A23', 'yaniella', 'ganilla', 'harine', 'xanilla', 'ganilla', 'canilla', 'kanilla', 'banilla', 'tanilla', 'janilla', '02323', 'daligill', '23545', '4anine', 'Vanilla', '4anilla', 'lanilla', 'Canilla', 'sanilla', 'tinie', 'Mingella', 'wanilill', '12555', 'nanilla', 'sangilil', 'alingel', 'tiligel', 'wanilie', '4anilla', 'laniella', 'Aanilla', 'ganilla', 'Lanilla', 'janilla', '023232', 'ganilla', 'Aanilla', 'maniella', 'zingella', 'banilla', 'nanilla', 'vanilla', 'janilla', '23555', '235555', '3232323', 'mingella', '22355', 'lingella', '02323', 'Lanine', 'tanilla', 'yanilill', '02323', '52323', 'Sangilla', '23555', 'banilla', '62345', 'lanilla', 'uringe'] 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Fake data classification accuracy: 0.61\n",
      "DEBUG:root:Feeding genuine data...\n",
      "DEBUG:root:Total classification accuracy: 0.66\n",
      "INFO:root:Done training discriminator.\n",
      "INFO:root:Training generator...\n",
      "INFO:root:Done training generator.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0gggegeeggggggeggge', 'sggeggggggggggggggi', '2ggggggegggge3ggggg', '1gggggggggggggggggg', 'jgegggggggggggggggg', 'kgggegggggggegggggg', 'biegegggggggggggggg', 'aggggggggeggggggggg', 'igggggggggggggggggg', 'mggegg3gggegggggggg', 'Egggggggggggggggggg', 'kgggggggegggeggggge', '1ggggegggeggegggggg', 'Mggggggeggggggggggg', 'bgggggggggggggggggg', 'sggggegggggegergggg', 'wggggggggggeggggggg', 'aggggggggggggegggeg', 'Aggggggggggggggggg3', '1gggggggggggggggggg', 'yggggeggggeegggggge', 'mggeggggggggggggggg', 'rgggggggggggggggggg', '9gggggggggggggggggg', '6gggggggggggegegggg', 'sgggggggggggggggggg', 'jggggggegggeggggggg', 'lggggggggggggeggggg', '1gggggggggeggeggggg', 'jgggegggegggegegggg', '9gggggggggggggggggg', '0geggggggggggggggeg', 'mgggggggggggggggggg', 'pggg3eggggggggggggg', 'dgigggggggggggggggg', 'siggggggeggggggggge', 'igggggggggggggggggg', 'rggg3ggggggggeggggg', 'sgggggggggegggegggg', 'Agggggggggggggggggg', 'wgggggggeggggggggge', 'lggggeggggggggggggg', 'agggegggggggggggegg', 'sggggeggggggggggggg', 'eggggggggggeegggggg', 'jigggegggggggggggge', 'agggegggggggggggggg', 'eggegggggggggg3gggg', 'tigeggggggggggegggg', '1gggggggggggggggggg', '0geeggggggegggggggg', 'mggggeggggggggggggg', 'Sggggggggeggggggggg', 'wggeggggggggggggggg', '1ggggggeggggggggggg', 'ggegg3ggeggggeggggg', 'migegggegggeggggggg', 'kgggeggeegggggggggg', 'rgggggggggggggggegg', 'sggggggggggggggegge', 'ogggggeggggggegeggg', 'agggggegggggggegggg', 'aiggggggggggggggggg', 'cgggg3gggggggggggge', 'sggggeggegggggggggg', '6gggggggggggggggggg', '8gggggggggggegggggg', '9ggggggggggggggggeg', '2ggggggegggeggggggg', 'dgggggeggeggggggggg', 'iggggggggegeggggggg', 'oggeggeggeggggggggg', 'nggggggggeggggggggg', 'kgggggeggggggggggeg', 'wggggggggggggggggg3', 'cggeggggggggggggggg', 'ngggggggggggggggggg', '1ggggggggggge3egggg', 'mgggggggggegggggegg', 'iggggggggggggggiggg', 'cgggeggegggeggggggg', 'ggggegggggggg3geggg', 'iggggeggggegegg3egg', 'uggegggggggggeggggg', '8ggggggggggggggggge', 'kgggggegggegeegggge', '0gggeggggggegeg3ggg', 'vggggggegggegggggge', '0ggggegeggggegegggg', '0gggggggeggeggg3ggg', 'ggeeggggggggegggggg', 'cgggggggggggggggggg', 'nigggeggggggggggggg', 'agegggggggggggggggg', 'cgggggggggggegggggg', 'mgggggggggggggggggg', 'rggggggggggggggggeg', 'bggggggggg3eggggggg', 'jgggggggggggggggggg', 'mgggegggggegg5ggggg'] 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:----------------- 4 / 5 -----------------\n",
      "INFO:root:Training discriminator...\n",
      "DEBUG:root:Feeding generated data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['burist', 'buris', 'goo', 'iner', 'saris', 'furis', '023', 'darist', '4and', 'joos', 'ander', 'furis', 'karis', 'maris', 'turis', 'loo', 'ous', 'yuster', 'furis', 'Cane', '423', '123', 'Eand', '422', 'karis', 'veris', 'xuris', 'Dand', 'guris', 'eris', '0238', '223', '8oo', '1', 'indis', '023', 'turi', 'coos', 'Lante', 'karis', '022', 'sarist', 'waris', 'turis', '123', 'xurer', 'inder', 'kand', '223', 'Aan', '0oo', '523', \"'and\", 'loos', 'coos', 'hori', 'loo', 'Sand', 'saris', 'joos', 'eroo', 'furis', '023', 'turis', 'ander', 'nand', 'anis', '323', 'nand', 'buri', '923', 'uuster', 'maris', 'Land', 'coos', 'ando', 'guris', 'anin', 'nand', '223', 'loo', 'paris', 'Zand', 'goos', 'loo', 'buris', 'karist', 'joos', 'coos', 'joos', 'inder', 'ando', 'sande', 'Pand', 'maris', 'Eande', '023', '023', 'furis', 'rarin'] 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Fake data classification accuracy: 0.65\n",
      "DEBUG:root:Feeding genuine data...\n",
      "DEBUG:root:Total classification accuracy: 0.73\n",
      "INFO:root:Done training discriminator.\n",
      "INFO:root:Training generator...\n",
      "INFO:root:Done training generator.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mrrrrirrcccrrcccccc', '2rrrrrrccrrccccrrcc', '0rrrrrrrrcccrrccccc', 'rirrrrrrcccrrccccrr', 'dirrrrrrccrrrcccrrc', 'errrrrrrcccrrcccccc', 'kirrrrrcrrccccraccc', 'crrrrrrirrcccrrccrr', 'Arrccrrrrcccrrccccc', 'Srrrrrccrrrcacccccc', 'frrrrrrrccrrccccrrc', 'dirrccrrrccccrrcccr', 'tirrrrcccrrccccrrcc', 'pirrrrrrcccrrrccccc', 'arrrrrrrccrrccccccc', 'Wrrrrrrrcccccrrcccr', 'orrrrrrrcccrrcccccc', 'Trrcrrccrrrccccrrcc', 'nirrrrrrrcccrrccrrc', 'bircrrrrccrrccccccc', 'Crrrrrrrccrrcccrrcc', 'riirrrrrccccrrcccrr', '9rrrrrrrcrrrccccccc', '1icrrrrrrccrrcccccc', 'prrrrrrrccrrrccrrcc', 'arrrrrrrccrrcccccac', 'arrcrrrrcccrrcccccc', 'jirrrrrrccrrccccrrc', 'arccrrrrccrrrcccccc', '4rrrrrrrccrrccccccc', 'licrrrrrccrrccccccc', 'pirrrrrrcccrrcccccr', 'gicrrrrrccrrccccccc', '2rrrrrrrccrrccccccc', 'rirrrrrraccrrcccccr', 'sirrrrrrccrrcrcrccc', 'wirrrrrrarccrrccrrc', '1irrrrrcarcccrrcccc', 'irrrrrrrcccrrccrrcc', 'nirrccrrrcccrrccccc', 'crcrrrirrcrrccccccc', 'urrrrrrrccccrrccccc', 'trrrrrrrccrrccccccc', 'Crrrrcrcrrracccccrr', 'lirrrrrrcrrcccccccc', 'crrirrrrccrrccrrccc', 'nircrrrrccrrccccccc', 'arcrrrrirrcccrrcccc', 'crrrrrrrccrrccccccc', '0rrrrcrrrcccrrccccc', 'Trrrrrrrcrrcrcrcccc', 'dircrrrrccrrccccccc', 'crrrrrrrccrrccrrccc', 'kirrrrrrcccrccccccc', 'Nrrrrrrrcccrrcccrrc', 'mirrrrrrcccrrcccccc', 'mirrrrrrcccrrcccccr', 'Prrrrrrrrcccrcrcccc', 'Srcrrrrrccrrccrrrrc', 'birrcrrccrrccaccccc', 'arrrrrrccrrccccrrcr', 'hirrrrirrcccracrccr', 'scrrcrrrrcccrrccccc', 'jicrrrrrccrcccrrccc', 'tirrrrrrccrrccccccc', 'pirrrrrrcrrcccccccc', 'birrrrrrccrccccrrcc', 'Jrrrrrrrrcccrrccccc', 'mirrcccrrrcccrrcccc', 'sirrrrrrccrrccccrcc', 'crrrrrrrccrrcccccrc', '3rcrrrrrccrrcrirccc', '5rrrrrrrcccrcccccrc', 'yrcrrrrrrcccrrccccc', '8rrrrrrrcccrrcccccr', '3rrrrrrrrccrrcccrrc', '0rrrrrrrccrrcccaccc', '0rrrrrrrrccccrrcccr', 'jirrrcrrrcccrrccccc', 'rirrrrrrrcccrrccccc', 'tirrcrrrrcccrrcccac', 'crrrrrrrccrrcccccac', '6rrrrrccrrrcrcccccc', 'crrrcrrrrcccrrccccc', 'xirrrrrrccccaccccrr', '2rrcrrrrccrrccaccrr', 'lirrrrrrcccrrrccccc', 'sirrrrrrccccrrccccc', 'pirrrrrrccrracccccc', '0rrrrrrrccrrccccccc', 'mirrrcrrrcccrrccccr', 'Jrrrrrccrrrcrcccccc', 'sirrrirccrrcccccccc', 'birrrrrrrrccccrrcrc', 'errrrrrrcccrcrrcccc', 'errrrrrrcrrccccrrcc', 'arrrcrrrrcccrrcrcrc', '4irrrrrrrcccrrccccc', 'errrrrrrcccrrcrccca', 'dirrcrcrcccrrcccccc'] 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:----------------- 5 / 5 -----------------\n",
      "INFO:root:Training discriminator...\n",
      "DEBUG:root:Feeding generated data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['123', '#arine', 'alline', 'janane', 'bana', '6ane1', 'perine', 'thamine1', 'dana', 'nana', 'hana', 'mana', 'shine', 'mana', 'shanel', 'anine', 'Jhine', 'rana', '0ane1', 'hana', '123', '1236', '5arane', 'alline1', 'mana', 'kana', 'verine', 'lone123', 'anine', '0ane123', 'pane1', 'zane1123', '0ana', 'harine', 'inalil', 'anille', 'kana', 'dane1', '0ane1', 'Rane1', 'yana', 'lone1', 'mana', '4hane', 'bana', '3anel', 'jana', 'Iana', 'dana', 'harine', '0ane1', '0anel', 'kana', 'bana', 'jone1', '0ane1', 'anine', 'bana', 'rana', 'Lana', 'jana', 'Jane123', 'jana', 'mana', 'anine', '3hane1', 'anine', 'pane1', 'tane1', '5ane1', 'shine', 'shane', '*ana', 'rana', '7ane123', 'elane', 'anelle', 'salle1', 'onele', 'jone1', '238', 'lone1', '6ane1', 'Canall', '7ane1', '120', '0ane1', 'jaminel', 'mana', '+ana', 'lone1', '9arane', 'banie1', '0123', 'rana', '0ane1', '23', 'jana', '123', 'zane123'] 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Fake data classification accuracy: 0.78\n",
      "DEBUG:root:Feeding genuine data...\n",
      "DEBUG:root:Total classification accuracy: 0.815\n",
      "INFO:root:Done training discriminator.\n",
      "INFO:root:Training generator...\n",
      "INFO:root:Done training generator.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bSSSSSSSSSISSSSSSSS', 'kSSSSSSSrrSSSSSSSSS', 'DSSSSSSSSSSSSSSISSS', 'bSSSSSSSSSSSSSSSSSI', 'pSSSSISSSSSSSSSSSSS', '0SSSISSSISSSSSSSSSI', 'sSSSSSSSSSSSSSSSSSS', 'ASSSSSSSSSSSSSSSSSS', '0SSSSSSSSSSSSSSSSSS', 'kSSrISSSSSSSSSSSSSS', 'sSSSSISSSSSSSSSSSSS', 'pSSISSSSSSSSSSSSSSS', 'iSSSSSSSSSSIISSSSSS', '9SSSISSSSSSSSSSSSSS', '2ISSSSSSSSSSSSSSSSS', 'sSSSSSSISSSSSSSSSSr', '3SISSSSSSSSSSSSSISI', 'aSSSISSSSrSSSSSSSSS', 'kSSSISSSSISSSSSSSSS', 'dSSSSSSSSSSSSSSSSSS', '1SSSSSSSSSSSSSSSISS', 'sSSISSISSSSSSSSSSSS', 'hSSSSSISSSSSSSSSSSS', 'sSISSSSSSSSSSSISSSS', 'rSSSSSSSSSSSSSSISSS', '7ISSSSSSSSSrSSISSSS', 'pSSSSSSSISSSSSSSSSS', 'JSSSSSISSSSISSSSSSS', '3SSSSSSSSSSSSSSSSSS', 'aSSSISSSSSSSrSSSSSS', 'jSSSSSSSSSISSSSSSSS', 'pSSSSSSSSSSSSSSSSSS', 'fIISSSSSISSSSSSISSS', 'kSSSSSSSSSSSSIIIISS', '4SSSSSSISSSSSSSSSSS', 'ISSSSSSSSSSSSSSSSSS', 'bSSISSSSSSSSSSSSSIS', '2SSSSSSSgSSISSSSSSS', 'cISSSSSIISSSSSSSISS', 'kSSSSISSSSSSSSSSSSS', '6SSSSSSSSSSSSSSSSSS', 'TSSSSSSSSSSSSSSSSIS', 'cSSSSSSSSSSSSSSSSSS', '0SSSrSSSSIISSSSSSSS', 'jSSSSSSISSSSISSSSSS', '0SSSSSSSSSSSSSSSSIS', '7SSISISISSSSSSSSSSS', 'dSSSSSSSSSSSSSSSSSS', '3SSSSSSSSSSSSSSSSSS', 'cSSSSISSSSSSSSSSSIS', 'mSSISSISSSSrSISSSSS', '0SISSSISSSISSSISSSS', 'eISSSSISrSSSSSSSSSS', 'tSSSSSSSSSSISSSSISI', 'fSSSSSSSSSIIISSSISS', 'SSSSSSSSSSISSSSSSSS', 'cSSSSSSSSSSSSSSSSSS', 'gSSSSISSISSSSSSSSSS', 'JSSSSSSSSIrSSSSSSSS', 'gSSSSSSSSSSSSSSSSSS', 'pSSISSISSSSSSSSSSSS', 'sSSSSSSSSSSSSSSSSSS', 'eSISISSSISSSSSSSISS', 'sSSSSISSSSSSISSSSSS', 'cSSSSSSSSSSSSSSSISS', 'DSISISSISSISSSSSSSS', 'tSSSSSSSSSSISSSSSSS', 'kSSSSSSSSSSSSSSSSSS', 'iSrSISISSISSSSSSSSS', 'kSSSSSSISIIISSSSSSS', '2SSSSSSSSSSSSSSSSSS', '1SSSSSSSISSISISSSSS', 'nISSSIISSSISSSISSSS', 'tSSSSSSSSSSSSSSSSSI', '9SSSSISSSSSSSSSSSrS', 'pSISrSSSSSSSSSSSSSS', 'kSSSSSSSISSSSSSSSSS', 'lISSSSSSSSISSSSSSSS', 'CSIIISSSSISSSSSSSIS', 'oSSSSISSSSSSSSSSSIS', 'mSSSSSSSSSSSSSSSSSS', '4SSSSSISSSSSSSSSSSS', 'bSSSSISSSISISSSgSSS', 'gSSSSSSSSSSSSSSSSSS', 'mSSSSISSSSSSSSSSSSS', 'sSISSSSSSSSSSSSSSSS', 'cSSSSSSSSSSSSSSSSSS', 'mSSSSSSSSSSSSSSSSSS', 'wSSSSSSSSSSSSSSSSSS', '7SSSSSSISSSSSISSSSS', 'OSSSrSSSSrSSSSSSIIS', 'jSSSSSSSSSSSSSSSSSS', 'nSSSSSSISSSSSSSSSSS', '1SSSSSISSSSISSSSSSS', 'lSSrISSSSSISSSSSSSS', 'fSISSSSSSSSISSSSSSS', 'mSSSISSSISSSSSISSSI', '0SISSSSSSSSSSSSSSSS', 'aSSSSSSSISSSSSISSSS', '1SSSSSSSSSSSSSSSSSS'] 5\n",
      "['gusshes', '2000', 'bana', '6usshes', 'rane', '0000', '0000', 'shess', 'lovin', 'tanes', '5000', 'rana', 'chess', 'manes', 'anen', 'panes', 'fusshe', '2000', 'jess', 'wanes', 'kanes', 'kanes', 'hanes', 'gusshess', 'chess', 'danes', 'chess', 'danes', 'shesshes', 'Justes', '0000', 'nanes', 'ones', 'shess', 'panes', 'hussha', 'chess', 'chess', 'zares', 'Muness', 'sanes', 'nanes', 'panes', 'besshess', '12000', 'anan', 'banes', 'paness', 'resshes', '7000', 'gusshes', '0000', 'nanan', 'anan', 'ranes', 'aless', 'cheles', 'hess', 'tane', '000', '1230', 'shess', 'isshes', '0usshes', '9000', 'loves', '6hess', 'sane', 'pares', 'fusses', 'shess', 'jana', '1230', 'anan', 'wanes', '8000', 'Busshess', '1230', 'jara', '7000', 'janes', '800', 'panes', '1230', '8000', 'lovin', 'maneshe', 'Lusshes', '4usshes', 'shess', 'ines', 'banes', '0000', 'Musshes', 'Zusshes', '*usshe', 'danes', 'Ausshes', 'pares', 'vesshes'] 5\n"
     ]
    }
   ],
   "source": [
    "logger.setLevel(logging.DEBUG)\n",
    "logging.info(\"---------- Adversarial Training ----------\\n\")\n",
    "\n",
    "n_adv_train = 5\n",
    "n_pass = 100\n",
    "n_train_gen = 1000\n",
    "\n",
    "for i in range(1, n_adv_train + 1):\n",
    "    logging.info(\"----------------- %d / %d -----------------\" % (i, n_adv_train))\n",
    "    logging.info(\"Training discriminator...\")\n",
    "    \n",
    "    logging.debug(\"Feeding generated data...\")\n",
    "    correct = 0\n",
    "    for j in range(n_pass):\n",
    "        password_tensor = g.generatePassTensor()\n",
    "        category_tensor = torch.tensor([0], dtype = torch.long)\n",
    "        output, loss = d.train(password_tensor, category_tensor)\n",
    "        if output[0][0] > output[0][1]:\n",
    "            correct += 1\n",
    "    \n",
    "    logging.debug(\"Fake data classification accuracy: \" + str(correct / n_pass))\n",
    "\n",
    "    \n",
    "    logging.debug(\"Feeding genuine data...\")\n",
    "    for j in range(n_pass):\n",
    "        password_tensor = P.passwordToInputTensor(p.poopPassword())\n",
    "        category_tensor = torch.tensor([1], dtype = torch.long)\n",
    "        output, loss = d.train(password_tensor, category_tensor)\n",
    "        if output[0][0] < output[0][1]:\n",
    "            correct += 1\n",
    "        \n",
    "    logging.debug(\"Total classification accuracy: \" + str(correct / n_pass / 2))\n",
    "    logging.info(\"Done training discriminator.\")\n",
    "    \n",
    "    \n",
    "    logging.info(\"Training generator...\")\n",
    "    for j in range(n_train_gen):\n",
    "        g.train(d, p)\n",
    "    \n",
    "    logging.info(\"Done training generator.\\n\")\n",
    "    \n",
    "    print(g.generate_N(p, 5))\n",
    "    for i in range(pre_train_iters):\n",
    "        pas = p.poopPassword()\n",
    "        input_tensor = P.passwordToInputTensor(pas)\n",
    "        target_tensor = P.passwordToTargetTensor(pas)\n",
    "        output, loss = g.pre_train(input_tensor, target_tensor)\n",
    "    print(g.generate_N(p, 5))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.pyplot:Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(loss_trend)\n",
    "#plt.savefig('pictures/rnn-rnn-loss.png',dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.LogSoftmax(dim=1)\n",
    "loss = nn.NLLLoss()\n",
    "# input is of size N x C = 3 x 5\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "# each element in target has to have 0 <= value < C\n",
    "target = torch.tensor([1, 0, 4])\n",
    "output = loss(m(input), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['marin',\n",
       " '0anda',\n",
       " ',anda',\n",
       " 'lollon',\n",
       " 'rinda',\n",
       " 'garin',\n",
       " 'nalin',\n",
       " 'paran',\n",
       " 'Panda',\n",
       " '2228',\n",
       " 'arinda',\n",
       " 'julin',\n",
       " '4anan',\n",
       " '12222',\n",
       " '4arin',\n",
       " 'marin',\n",
       " 'barin',\n",
       " '22222',\n",
       " '9ana',\n",
       " 'xanda',\n",
       " 'elondan',\n",
       " 'narind',\n",
       " 'paress',\n",
       " '6anda',\n",
       " 'aranda',\n",
       " '7anda',\n",
       " 'juna',\n",
       " 'marin',\n",
       " 'julin',\n",
       " 'elondan',\n",
       " 'sana',\n",
       " 'julond',\n",
       " 'oudan',\n",
       " 'tarin',\n",
       " '0arin',\n",
       " 'qanda',\n",
       " 'lollin',\n",
       " 'darin',\n",
       " 'arilo',\n",
       " 'yollin',\n",
       " 'carin',\n",
       " 'carin',\n",
       " 'Aanda',\n",
       " 'ianan',\n",
       " 'barin',\n",
       " 'Banda',\n",
       " 'lollind',\n",
       " 'tarin',\n",
       " 'sana',\n",
       " '8anda',\n",
       " '3anda',\n",
       " 'elonda',\n",
       " 'juna',\n",
       " '12222',\n",
       " '0inda',\n",
       " 'danda',\n",
       " 'rinda',\n",
       " 'Aulond',\n",
       " 'handa',\n",
       " '0anda',\n",
       " 'Mandan',\n",
       " '22222',\n",
       " 'rinda',\n",
       " 'pandes',\n",
       " 'zindes',\n",
       " 'harin',\n",
       " 'sana',\n",
       " 'karin',\n",
       " 'julin',\n",
       " 'barin',\n",
       " 'Barin',\n",
       " 'Ianda',\n",
       " 'garin',\n",
       " '5anda',\n",
       " '22222',\n",
       " 'alondan',\n",
       " 'sana',\n",
       " '3andan',\n",
       " '12822',\n",
       " '0arin',\n",
       " 'julin',\n",
       " '12222',\n",
       " 'marin',\n",
       " 'julilo',\n",
       " 'parin',\n",
       " 'carin',\n",
       " 'olonda',\n",
       " '0indes',\n",
       " 'arindan',\n",
       " 'elondes',\n",
       " '0inda',\n",
       " 'narin',\n",
       " 'garin',\n",
       " '5inda',\n",
       " 'sana',\n",
       " 'marin',\n",
       " 'carind',\n",
       " 'sarin',\n",
       " '3andes',\n",
       " 'naran']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(g.generate_N(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0.]],\n",
       "\n",
       "        [[0., 0.]],\n",
       "\n",
       "        [[0., 0.]],\n",
       "\n",
       "        [[0., 0.]],\n",
       "\n",
       "        [[0., 0.]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((torch.zeros(4,1,2), torch.zeros(1,1,2)), -3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0.]],\n",
       "\n",
       "        [[0., 0.]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(torch.zeros(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch]",
   "language": "python",
   "name": "conda-env-.conda-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
